<!doctype html><html lang="en"><head><title>Generalizing the Coin Toss Markov Model - Jim Killingsworth</title><meta charset="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta name="description" content="This is a continuation of the series on weighted coin toss games. In previous posts, we explored variations of the weighted coin toss game using two, three, and four flips per round. In each variation, the game was described using a Markov model with a fixed number of coin toss events. This post presents a generalized form of the Markov model that can be used to model a game with an arbitrary number of coin toss events. I also show a few examples using a model of the coin toss game with ten flips per round."/><base href="/"/><link rel="canonical" href="https://jkillingsworth.com/2021/02/25/generalizing-the-coin-toss-markov-model/"/><link rel="icon" href="./static/favicon.ico" type="image/x-icon"/><link rel="icon" href="./static/favicon-256.jpg" sizes="256x256"/><link rel="preload" href="./static/fonts/open-sans-v20-latin-700.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/lora-v17-latin-regular.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/lora-v17-latin-italic.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/roboto-mono-v13-latin-regular.woff2" as="font" crossorigin/><link rel="preload" href="https://www.google-analytics.com/analytics.js" as="script"/><script src="https://www.googletagmanager.com/gtag/js?id=UA-114299226-1" async></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag("js", new Date());
  gtag("config", "UA-114299226-1", { "send_page_view": true });
</script><style>@font-face{font-display:swap;font-family:"Open Sans";font-style:normal;font-weight:700;src:local("Open Sans Bold"),local("OpenSans-Bold"),url(./static/fonts/open-sans-v20-latin-700.woff2) format("woff2"),url(./static/fonts/open-sans-v20-latin-700.woff) format("woff")}@font-face{font-display:swap;font-family:"Lora";font-style:normal;font-weight:400;src:local("Lora Regular"),local("Lora-Regular"),url(./static/fonts/lora-v17-latin-regular.woff2) format("woff2"),url(./static/fonts/lora-v17-latin-regular.woff) format("woff")}@font-face{font-display:swap;font-family:"Lora";font-style:italic;font-weight:400;src:local("Lora Italic"),local("Lora-Italic"),url(./static/fonts/lora-v17-latin-italic.woff2) format("woff2"),url(./static/fonts/lora-v17-latin-italic.woff) format("woff")}@font-face{font-display:swap;font-family:"Roboto Mono";font-style:normal;font-weight:400;src:local("Roboto Mono"),local("RobotoMono-Regular"),url(./static/fonts/roboto-mono-v13-latin-regular.woff2) format("woff2"),url(./static/fonts/roboto-mono-v13-latin-regular.woff) format("woff")}
/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:0.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace, monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace, monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}button,[type="button"],[type="reset"],[type="submit"]{-webkit-appearance:button}button::-moz-focus-inner,[type="button"]::-moz-focus-inner,[type="reset"]::-moz-focus-inner,[type="submit"]::-moz-focus-inner{border-style:none;padding:0}button:-moz-focusring,[type="button"]:-moz-focusring,[type="reset"]:-moz-focusring,[type="submit"]:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:0.35em 0.75em 0.625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type="checkbox"],[type="radio"]{box-sizing:border-box;padding:0}[type="number"]::-webkit-inner-spin-button,[type="number"]::-webkit-outer-spin-button{height:auto}[type="search"]{-webkit-appearance:textfield;outline-offset:-2px}[type="search"]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}template{display:none}[hidden]{display:none}
html{box-sizing:border-box;overflow-y:scroll}*,*::before,*::after{box-sizing:inherit}body{font-family:"Lora", "Georgia", serif;font-weight:normal;background:#fff;color:#000;display:flex;flex-flow:row wrap;font-size:12pt;justify-content:space-between;line-height:1.5;margin:0 auto;width:90%}body>*{flex:0 100%}body>header{font-size:21pt;margin:10px 0}body>footer{border-top:3px solid gray;font-size:10pt;font-style:italic;padding:16px 0}header,nav,h1,h2{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold}header a,nav a,h1 a,h2 a{color:inherit}a{color:blue;text-decoration:none}a:hover{color:blue;text-decoration:underline}strong{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold}svg{fill:currentColor}.navmenu{border-top:3px solid gray;border-bottom:1px solid #ccc}.navmenu #toggle{float:right;height:24px;margin:4px 0;width:24px}.navmenu #toggle+label{color:transparent;cursor:pointer;display:block;padding:4px 0;position:relative;user-select:none;-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none}.navmenu #toggle+label::before{background:#fff;background-size:24px;content:"";float:right;height:24px;left:24px;position:relative;width:24px}.navmenu #toggle+label::after{content:"Menu";left:0;padding:0 16px;position:absolute}.navmenu #toggle+label{border-bottom:none}.navmenu #toggle+label::before{background-image:url("./static/chevron-down.svg")}.navmenu #toggle+label::after{color:#000}.navmenu #toggle~ul{height:0;visibility:hidden}.navmenu #toggle:checked+label{border-bottom:1px solid #e6e6e6}.navmenu #toggle:checked+label::before{background-image:url("./static/chevron-up.svg")}.navmenu #toggle:checked+label::after{color:gray}.navmenu #toggle:checked~ul{height:auto;visibility:visible}.navmenu ul{display:flex;flex-flow:column wrap;list-style-type:none;justify-content:flex-start;margin:0;overflow:hidden;padding:0}.navmenu ul>li{flex:none}.navmenu ul>li a{display:block;padding:4px 16px}.navmenu ul>li a:hover,.navmenu ul>li a:focus{background:gray;color:#fff}.content{max-width:720px}.content header,.content footer,.content h1,.content h2,.content p,.content ul,.content figure{margin:24px 0}.content h1{font-size:18pt}.content h2{font-size:12pt}.content footer{font-style:italic}.content p:last-of-type::after{clear:both;content:"";display:block}.content ul{padding-left:16px}.content ul>li{margin:12px 0}.content figure{max-width:90vw}.content figure>img{display:block}.content .fig-chart{padding-top:56.25%;page-break-inside:avoid;position:relative}.content .fig-chart>img{max-height:100%;max-width:100%;position:absolute;top:0}.content .fig-latex{overflow-x:auto}.content .fig-latex>img{margin:0 16px}.content .fig-pic-l>img,.content .fig-pic-r>img{margin:0 auto;max-width:100%;object-fit:cover}.content .button{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold;background:#e6e6e6;color:inherit;display:block;margin:24px 0;padding:4px 0;text-align:center}.content .button:hover,.content .button:focus{background:gray;color:#fff}.content .message header>h1{background:#ff0;display:inline-block;font-size:12pt;margin:0;text-transform:lowercase}.content .message header>h1::first-letter{text-transform:uppercase}.content .message header>h1::after{content:":"}.content .message p{font-style:italic}.content .newpost header>h1{background:#ff0;display:inline-block;font-size:12pt;margin:0;text-transform:lowercase}.content .newpost header>h1::first-letter{text-transform:uppercase}.content .newpost header>h1::after{content:":"}.content .newpost header>h2{font-size:18pt}.content .newpost a.readmore::after{content:" \00bb"}.content .newpost a:not(.readmore):not(:hover){color:inherit}.content .oldpost{margin:24px 0}.content .oldpost header>h1{display:none}.content .archive ul>li time{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:none;font-size:10pt}.content .contact label,.content .contact input[type="submit"]{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold;cursor:pointer;display:block;margin:16px 0}.content .contact label{margin-bottom:4px}.content .contact input[type="text"],.content .contact input[type="email"],.content .contact textarea{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:block;font-size:10pt;line-height:inherit;padding:4px;width:100%}.content .contact textarea{height:200px;max-width:100%;min-width:100%}.content .contact input[type="submit"]{padding:4px 40px}.content .comments{margin:24px 0 8px}.content .comments header>h2{display:none}.content .comments noscript{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:block;font-size:10pt;margin:-12px 0 24px}.sidebar header>h1{display:none}.sidebar header>h2{border-bottom:1px solid #ccc;border-top:3px solid gray;font-size:inherit;margin:0;padding:4px 0}.sidebar section{margin:24px 0}.sidebar section:first-of-type{margin-top:0}.sidebar .social-media ul{list-style:none;padding:0 0 0 16px}.sidebar .social-media ul>li a{display:inline-block}.sidebar .social-media ul>li a *{vertical-align:middle}.sidebar .social-media ul>li a span{margin:0 10px}.sidebar .social-media ul>li a svg{color:gray;height:48px;width:48px}.sidebar .social-media ul>li a:hover svg{color:inherit}.content p:not(.nojustify),.sidebar p:not(.nojustify){text-align:justify;word-spacing:-1px}.content p,.content ul,.sidebar p,.sidebar ul{line-height:1.667}@media only screen and (min-width: 600px){.content ul{padding-left:40px}.content ul>li{margin:0}.content figure{max-width:90vw}.content .fig-latex>img{margin:0 40px}.content .fig-pic-l>img{float:left;margin:0 24px 0 0}.content .fig-pic-r>img{float:right;margin:0 0 0 24px}.content .archive ul>li time{display:inline}body{max-width:720px;width:90%}body>header{font-size:24pt}.navmenu #toggle{display:none}.navmenu #toggle+label{display:none}.navmenu #toggle~ul{height:auto;visibility:visible}.navmenu ul{flex-flow:row wrap}.navmenu ul>li a{padding:4px 32px}}@media only screen and (min-width: 1200px){body{max-width:1200px}body>header{text-align:center}.content{flex:0 60%}.sidebar{flex:0 35%}.sidebar section:first-of-type{margin-top:40px}}@media only print{.content ul{padding-left:40px}.content ul>li{margin:0}.content figure{max-width:100vw}.content .fig-latex>img{margin:0 40px}.content .fig-pic-l>img{float:left;margin:0 24px 0 0}.content .fig-pic-r>img{float:right;margin:0 0 0 24px}.content .archive ul>li time{display:inline}body{display:block;margin:auto;width:100%}body>header{border-bottom:1px solid #ccc;border-top:3px solid gray;font-size:inherit;margin:0;padding:4px 0;text-align:left}.navmenu,.sidebar,.oldpost,.comments{display:none}}@page{margin:1in 1.25in}
</style></head><body><header><a href="./">Jim Killingsworth</a></header><nav class="navmenu"><input id="toggle" type="checkbox"/><label for="toggle">Enable menu</label><ul><li><a href="./"> Home </a></li><li><a href="./archive/"> Archive </a></li><li><a href="./about/"> About </a></li><li><a href="./contact/"> Contact </a></li></ul></nav><main class="content"><article><header><h1>Generalizing the Coin Toss Markov Model</h1></header><p>This is a con­tin­u­a­tion of the series on weighted coin toss games. In pre­vi­ous posts, we explored vari­a­tions of the weighted coin toss game using two, three, and four flips per round. In each vari­a­tion, the game was described using a Markov model with a fixed num­ber of coin toss events. This post presents a gen­er­al­ized form of the Markov model that can be used to model a game with an arbi­trary num­ber of coin toss events. I also show a few exam­ples using a model of the coin toss game with ten flips per round.</p><h2 id="markov-model-with-2-coin-tosses">Markov Model with 2 Coin Tosses</h2><p>Let’s start with a very sim­ple model of the coin toss game that uses only two flips of the coin per round. This is the model used in the pre­vi­ous post titled <a href="/2021/01/29/visualizing-saddle-points-and-minimums/"><em>Visu­al­iz­ing Sad­dle Points and Minimums</em></a>. Here is what the Markov model looks like:</p><figure class="fig-latex"><img width="259" height="355" alt="Figure 1" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-01-latex-1245136283.svg"></figure><p>In this mod­el, there are five pos­si­ble states that the sys­tem can be in and six pos­si­ble state tran­si­tions. Each arrow rep­re­sents a state tran­si­tion. The state dia­gram above can be rep­re­sented using a state tran­si­tion matrix:</p><figure class="fig-latex"><img width="352" height="171" alt="Figure 2" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-02-latex-2107167586.svg"></figure><p>This tran­si­tion matrix deter­mines the prob­a­bil­ity of mov­ing from one state to the next. This is a square matrix with a row and a col­umn for each state. The rows rep­re­sent the start­ing states, and the col­umns rep­re­sent the sub­se­quent states. We can also use a vec­tor with five ele­ments—one for each state—to rep­re­sent the prob­a­bil­ity of being in each one of the states at a par­tic­u­lar point in time. Since we always start in the zero state, the ini­tial vec­tor looks like this:</p><figure class="fig-latex"><img width="100" height="176" alt="Figure 3" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-03-latex-2435652580.svg"></figure><p>We can com­pute the prob­a­bil­ity of being in each one of the five states after the first coin toss by tak­ing the prod­uct of the state vec­tor and the state tran­si­tion matrix:</p><figure class="fig-latex"><img width="89" height="17" alt="Figure 4" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-04-latex-3937244012.svg"></figure><p>After the first coin toss, there are two pos­si­ble states that the sys­tem can be in. The prod­uct above works out to the following:</p><figure class="fig-latex"><img width="108" height="176" alt="Figure 5" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-05-latex-3817588834.svg"></figure><p>Since there are two flips of the coin per round, we can com­pute the final out­come dis­tri­b­u­tion by mul­ti­ply­ing the vec­tor above by the tran­si­tion matrix one more time:</p><figure class="fig-latex"><img width="89" height="17" alt="Figure 6" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-06-latex-2174669261.svg"></figure><p>After the sec­ond coin toss, there are three pos­si­ble states the sys­tem can be in. The prod­uct above works out to the following:</p><figure class="fig-latex"><img width="180" height="177" alt="Figure 7" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-07-latex-3641352764.svg"></figure><p>As you can see, for the final out­come, the sys­tem can only be in one of three out of the five pos­si­ble states after the sec­ond coin toss. The other two states only serve as inter­me­di­ate states that the sys­tem tran­si­tions through. Note that there is a pos­si­bil­ity that the sys­tem returns to the ini­tial state after the sec­ond coin toss.</p><h2 id="markov-model-with-3-coin-tosses">Markov Model with 3 Coin Tosses</h2><p>A slightly more com­pli­cated model is that of a coin toss game with three flips of the coin per round. This is the model used pre­vi­ously in the post titled <a href="/2020/08/16/visualizing-the-climb-up-the-hill/"><em>Visu­al­iz­ing the Climb up the Hill</em></a>. Here is what the Markov model looks like:</p><figure class="fig-latex"><img width="403" height="388" alt="Figure 8" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-08-latex-4279565530.svg"></figure><p>In this mod­el, there are seven pos­si­ble states that the sys­tem can be in and a total of ten pos­si­ble state tran­si­tions. The state dia­gram illus­trated above can be rep­re­sented with the fol­low­ing state tran­si­tion matrix:</p><figure class="fig-latex"><img width="481" height="248" alt="Figure 9" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-09-latex-2073593936.svg"></figure><p>This is a square matrix with seven rows and seven columns. We can also use a seven ele­ment vec­tor to rep­re­sent the like­li­hood of the sys­tem being in a par­tic­u­lar state at a given point in time. The ini­tial vec­tor looks like this:</p><figure class="fig-latex"><img width="100" height="253" alt="Figure 10" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-10-latex-3715729114.svg"></figure><p>We can mul­ti­ply this vec­tor by the tran­si­tion matrix three times to deter­mine where we might find the state of the sys­tem after three flips of the coin:</p><figure class="fig-latex"><img width="157" height="17" alt="Figure 11" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-11-latex-4210935829.svg"></figure><p>After the third coin toss, there are four pos­si­ble states the sys­tem can be in. The prod­uct above works out to the following:</p><figure class="fig-latex"><img width="321" height="253" alt="Figure 12" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-12-latex-0098461260.svg"></figure><p>The sys­tem can be in one of four pos­si­ble states for the final out­come. The other three states are inter­me­di­ate states that the sys­tem tran­si­tions through. Notice that the ini­tial state is not one of the final states since there is an odd num­ber of coin tosses in this case.</p><h2 id="generalized-markov-model">Generalized Markov Model</h2><p>In addi­tion to the two Markov mod­els out­lined above, you can also find a detailed dis­cus­sion of a model of the coin toss game with four flips per round in one of my ear­lier posts titled <a href="/2019/09/14/estimating-the-weights-of-biased-coins/"><em>Esti­mat­ing the Weights of Biased Coins</em></a>. All of these mod­els can be described by a gen­er­al­ized mod­el. Sup­pose we have a coin toss game with an arbi­trary num­ber of flips per round. We can rep­re­sent the gen­er­al­ized form of the Markov model with a state dia­gram that looks like this:</p><figure class="fig-latex"><img width="547" height="388" alt="Figure 13" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-13-latex-1749163253.svg"></figure><p>The total num­ber of states the sys­tem can be in depends on the num­ber of coin toss events. We can deter­mine the num­ber of states using the fol­low­ing equation:</p><figure class="fig-latex"><img width="353" height="87" alt="Figure 14" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-14-latex-2908301011.svg"></figure><p>The num­ber of states the sys­tem can be in deter­mines the size of the state tran­si­tion matrix. Since this can be an arbi­trar­ily large matrix, it is more prac­ti­cal to describe the con­tents of the matrix using an algorithm:</p><figure class="fig-latex"><img width="444" height="504" alt="Figure 15" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-15-latex-0574310166.svg"></figure><p>This is a square matrix with a nonzero value for every pos­si­ble state tran­si­tion in the Markov mod­el. We also need to define an ini­tial state vec­tor. Since there is only one ini­tial state, this vec­tor can be described with a very sim­ple algorithm:</p><figure class="fig-latex"><img width="287" height="216" alt="Figure 16" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-16-latex-1798102193.svg"></figure><p>Once we have a state tran­si­tion matrix and the ini­tial state vec­tor, we can com­pute the final out­come using the fol­low­ing formula:</p><figure class="fig-latex"><img width="96" height="19" alt="Figure 17" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-17-latex-2967125593.svg"></figure><p>The final out­come tells us how likely it is for each state to be the final state of the sys­tem after a sin­gle round of the coin toss game. We can also rep­re­sent the final out­come like this:</p><figure class="fig-latex"><img width="141" height="201" alt="Figure 18" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-18-latex-0779021729.svg"></figure><p>Each ele­ment con­tains the prob­a­bil­ity that the sys­tem ter­mi­nates in the cor­re­spond­ing state after the final coin toss. Since our model is sym­met­ri­cal about the ini­tial state, there is a sym­me­try to the result­ing val­ues in the final outcome.</p><h2 id="equality-constraints">Equality Constraints</h2><p>Given the model of the coin toss game described above, sup­pose we know the val­ues of the final out­come but not the val­ues of the weights of the biased coins. Start­ing with the final out­come—sometimes referred to as the tar­get dis­tri­b­u­tion—we can find a valid set of weights using the method of Lagrange mul­ti­pli­ers described in <a href="/2020/12/12/equality-constraints-and-lagrange-multipliers/"><em>Equal­ity Con­straints and Lagrange Multipliers</em></a>. To use this method, we need to come up with a set of equal­ity con­straints based on the mod­el. Let’s start with some equal­ity con­di­tions that must hold true:</p><figure class="fig-latex"><img width="297" height="63" alt="Figure 19" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-19-latex-0476095474.svg"></figure><p>The left­-hand side of these equa­tions rep­re­sents the value of the known tar­get dis­tri­b­u­tion for the cor­re­spond­ing state. The right-hand side rep­re­sents the com­puted result based on the val­ues of the weights of the biased coins. These equal­ity con­di­tions are true if we have a valid set of weights. Notice also the sym­me­try for states above and below the ini­tial state. We can leave out the dupli­cate con­di­tions because they are redun­dant. We can also elim­i­nate states that we know are never ter­mi­nal states. Con­sider the following:</p><figure class="fig-latex"><img width="171" height="45" alt="Figure 20" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-20-latex-1400889112.svg"></figure><p>These two sets con­tain even and odd num­bers, respec­tive­ly. We can select one or the other based on whether the num­ber of coin toss events per round is even or odd:</p><figure class="fig-latex"><img width="196" height="47" alt="Figure 21" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-21-latex-2429854235.svg"></figure><p>Using the selected set, we can deter­mine which states are never ter­mi­nal states. Non-ter­mi­nal states have a prob­a­bil­ity of zero in the final out­come. We know the fol­low­ing holds true, no mat­ter what weights are used for the biased coins:</p><figure class="fig-latex"><img width="122" height="19" alt="Figure 22" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-22-latex-3249740944.svg"></figure><p>We can elim­i­nate non-ter­mi­nal states from con­sid­er­a­tion because they have no bear­ing on the equal­ity con­straints needed for the method of Lagrange mul­ti­pli­ers. The total num­ber of equal­ity con­straints then is given by the following:</p><figure class="fig-latex"><img width="250" height="90" alt="Figure 23" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-23-latex-4228660138.svg"></figure><p>The num­ber of equal­ity con­straints is a func­tion of the total num­ber of coin toss events. We can estab­lish a set of equal­ity con­straints like this:</p><figure class="fig-latex"><img width="208" height="19" alt="Figure 24" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-24-latex-3596642742.svg"></figure><p>Each con­straint func­tion must be equal to zero. The func­tions we want to use here are func­tions that take the dif­fer­ence between the tar­get val­ues and the com­puted val­ues based on a given set of weights:</p><figure class="fig-latex"><img width="369" height="47" alt="Figure 25" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-25-latex-0019630622.svg"></figure><p>Using these equal­ity con­straints, we can con­struct a Lagrangian func­tion that can be used to find a valid set of weights:</p><figure class="fig-latex"><img width="208" height="50" alt="Figure 26" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-26-latex-2590746197.svg"></figure><p>We can use this Lagrangian func­tion to find a valid set of weights by apply­ing the opti­miza­tion and root find­ing meth­ods out­lined in pre­vi­ous posts.</p><h2 id="example-with-exponential-distribution">Example with Exponential Distribution</h2><p>Now let’s take a look at an exam­ple with ten coin toss events per round. Sup­pose we start with the fol­low­ing tar­get distribution:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 27" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-27-pmfunc-exponent.svg"></figure><p>We want to find a valid set of weights that yields this dis­tri­b­u­tion in the final out­come. We’ll start with the fol­low­ing ini­tial guess and iter­a­tively work towards a solution:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 28" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-28-biases-start-slope.svg"></figure><p>We can use the mul­ti­vari­ate form of New­ton’s method to find the weights for which the gra­di­ent of the Lagrangian func­tion is equal to zero. This method is described in detail in the post titled <a href="/2020/12/31/finding-the-roots-with-newtons-method/"><em>Find­ing the Roots with New­ton’s Method</em></a>. Here we apply the fol­low­ing iter­a­tive formula:</p><figure class="fig-latex"><img width="170" height="22" alt="Figure 29" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-29-latex-1337556357.svg"></figure><p>Note the use of the alter­na­tive nota­tion scheme above for the gra­di­ent of the Lagrangian func­tion. The Lagrangian func­tion we use in this exam­ple must have a con­crete def­i­n­i­tion of the scor­ing func­tion defined. In this exam­ple, we use two dif­fer­ent scor­ing func­tions, defined below.</p><p>Here is the def­i­n­i­tion of scor­ing func­tion A:</p><figure class="fig-latex"><img width="170" height="52" alt="Figure 30" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-30-latex-0054475002.svg"></figure><p>Here is the def­i­n­i­tion of scor­ing func­tion B:</p><figure class="fig-latex"><img width="177" height="52" alt="Figure 31" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-31-latex-0175326301.svg"></figure><p>Here is the solu­tion found using scor­ing func­tion A:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 32" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-32-biases-final-1.svg"></figure><p>Here is the solu­tion found using scor­ing func­tion B:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 33" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-33-biases-final-2.svg"></figure><p>Here are the num­ber of iter­a­tions required for each scor­ing function:</p><figure class="fig-latex"><img width="294" height="102" alt="Figure 34" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-34-latex-1522624424.svg"></figure><p>In both cas­es, the ini­tial guess is not too far from the opti­mal solu­tion. As with pre­vi­ous exam­ples using New­ton’s method, the sys­tem con­verges in very few iter­a­tions. Both solu­tions are very sim­i­lar, tak­ing on a sort of zigzag shape.</p><h2 id="example-with-triangular-distribution">Example with Triangular Distribution</h2><p>Let’s take a look at another exam­ple with ten coin toss events per round. Sup­pose we start with the fol­low­ing tar­get distribution:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 35" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-35-pmfunc-triangle.svg"></figure><p>We want to find a valid set of weights that yields this dis­tri­b­u­tion in the final out­come. We’ll start with the fol­low­ing ini­tial guess and iter­a­tively work towards a solution:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 36" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-36-biases-start-equal.svg"></figure><p>To find a valid set of weights, we’ll use the mul­ti­vari­ate form of New­ton’s method like we did in the last exam­ple. But this time, we’ll include a damp­ing fac­tor to slow down the con­ver­gence. Here is the iter­a­tive formula:</p><figure class="fig-latex"><img width="179" height="22" alt="Figure 37" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-37-latex-3785635947.svg"></figure><p>We’ll use a damp­ing fac­tor of ten percent:</p><figure class="fig-latex"><img width="55" height="17" alt="Figure 38" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-38-latex-2213068255.svg"></figure><p>The damp­ing fac­tor slows down the con­ver­gence and pre­vents the method from over­shoot­ing. In this par­tic­u­lar exam­ple, the method fails the con­verge with­out slow­ing down the iter­a­tive process. The use of the damp­ing fac­tor would not be nec­es­sary if we started with an ini­tial guess closer to the final solution.</p><p>Here is the solu­tion found using scor­ing func­tion A:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 39" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-39-biases-final-3.svg"></figure><p>Here is the solu­tion found using scor­ing func­tion B:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 40" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-40-biases-final-4.svg"></figure><p>Here are the num­ber of iter­a­tions required for each scor­ing function:</p><figure class="fig-latex"><img width="294" height="102" alt="Figure 41" src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-41-latex-0075974125.svg"></figure><p>The damped ver­sion of New­ton’s method requires many more iter­a­tions to con­verge than it does with the undamped ver­sion used in the pre­vi­ous exam­ple. As with the pre­vi­ous exam­ple, the two solu­tions are very sim­i­lar to one anoth­er, this time tak­ing on a slanted shape.</p><h2 id="shortcomings">Shortcomings</h2><p>The meth­ods used here allow us to find a valid set of weights for a given tar­get dis­tri­b­u­tion using a model of the coin toss game that allows for an arbi­trary num­ber of coin toss events. We used the method of Lagrange mul­ti­plier to set up an equa­tion, and we used New­ton’s method to solve the equa­tion. But these meth­ods are not with­out their short­com­ings. As we saw in the pre­vi­ous sec­tion, we had to adapt the iter­a­tive for­mula with a damp­ing fac­tor to get the iter­a­tive process to con­verge to a solution.</p><p>Besides the over­shoot prob­lem, there are cases where these meth­ods might con­verge to a solu­tion out­side the accept­able range of val­ues. The weights of the biased coins must always be a prob­a­bil­ity between zero and one. There is noth­ing in the method of Lagrange mul­ti­pli­ers that lim­its val­ues to a par­tic­u­lar range. I might have to explore an approach using <a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions">Karush–Kuh­n–­Tucker conditions</a> to include inequal­ity constraints.</p><p>Another prob­lem is run­time per­for­mance. With the imple­men­ta­tion used in this post, find­ing the solu­tion for a model with ten coin toss events per round takes a cou­ple of sec­onds to exe­cute on my cur­rent hard­ware. A model with one addi­tional coin toss event per round takes about twice the amount of time to exe­cute. This imple­men­ta­tion seems to have an expo­nen­tial time com­plex­i­ty. There is no par­al­lelism, and I have made no attempt at per­for­mance tun­ing. But I do think there is room for improve­ment. There might also be other approaches that offer a good enough solu­tion. Ide­al­ly, I would like to be able to solve for mod­els with twenty or even fifty flips per round.</p><p class="nojustify"><a href="https://github.com/jkillingsworth/jkillingsworth.com/tree/master/src/2021-02-25-generalizing-the-coin-toss-markov-model">Accom­pa­ny­ing source code is avail­able on GitHub.</a></p><footer><time datetime="2021-02-25">February 25, 2021</time></footer></article><section class="comments"><header><h2>Comments</h2></header><script>
    var disqus_config = function () {
      this.page.url = "https://jkillingsworth.com/2021/02/25/generalizing-the-coin-toss-markov-model/";
      this.page.title = "Generalizing the Coin Toss Markov Model";
      this.page.identifier = "/2021/02/25/generalizing-the-coin-toss-markov-model/";
    };
    function disqus_show() {
      var d = document, s = d.createElement("script");
      s.src = "https://jkillingsworth.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    }
    function anchor_blur() {
      var a = document.getElementById("comments");
      a.innerText = "Comments";
      a.blur();
    }
    function disqus() {
      disqus_show();
      anchor_blur();
    }
  </script><a href="javascript:disqus();" id="comments" class="button">Show comments</a><div id="disqus_thread"></div><noscript> Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript></section></main><aside class="sidebar"><header><h1>Sidebar</h1></header><section class="social-media"><header><h2>Social Media</h2></header><ul><li><a href="https://www.linkedin.com/in/jkillingsworth/"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 512 512"><path d="M417.2 64H96.8C79.3 64 64 76.6 64 93.9V415c0 17.4 15.3 32.9 32.8 32.9h320.3c17.6 0 30.8-15.6 30.8-32.9V93.9C448 76.6 434.7 64 417.2 64zM183 384h-55V213h55v171zm-25.6-197h-.4c-17.6 0-29-13.1-29-29.5 0-16.7 11.7-29.5 29.7-29.5s29 12.7 29.4 29.5c0 16.4-11.4 29.5-29.7 29.5zM384 384h-55v-93.5c0-22.4-8-37.7-27.9-37.7-15.2 0-24.2 10.3-28.2 20.3-1.5 3.6-1.9 8.5-1.9 13.5V384h-55V213h55v23.8c8-11.4 20.5-27.8 49.6-27.8 36.1 0 63.4 23.8 63.4 75.1V384z"></path></svg><span>LinkedIn</span></a></li><li><a href="https://github.com/jkillingsworth/"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 512 512"><path d="M256 32C132.3 32 32 134.9 32 261.7c0 101.5 64.2 187.5 153.2 217.9 1.4.3 2.6.4 3.8.4 8.3 0 11.5-6.1 11.5-11.4 0-5.5-.2-19.9-.3-39.1-8.4 1.9-15.9 2.7-22.6 2.7-43.1 0-52.9-33.5-52.9-33.5-10.2-26.5-24.9-33.6-24.9-33.6-19.5-13.7-.1-14.1 1.4-14.1h.1c22.5 2 34.3 23.8 34.3 23.8 11.2 19.6 26.2 25.1 39.6 25.1 10.5 0 20-3.4 25.6-6 2-14.8 7.8-24.9 14.2-30.7-49.7-5.8-102-25.5-102-113.5 0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8 0 0 1.6-.5 5-.5 8.1 0 26.4 3.1 56.6 24.1 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 30.2-21 48.5-24.1 56.6-24.1 3.4 0 5 .5 5 .5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6 0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5 0 30.7-.3 55.5-.3 63 0 5.4 3.1 11.5 11.4 11.5 1.2 0 2.6-.1 4-.4C415.9 449.2 480 363.1 480 261.7 480 134.9 379.7 32 256 32z"></path></svg><span>GitHub</span></a></li></ul></section></aside><footer> &copy; 2018&ndash;2021 Jim Killingsworth. All rights reserved. </footer></body></html>