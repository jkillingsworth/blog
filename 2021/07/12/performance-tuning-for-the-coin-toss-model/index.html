<!doctype html><html lang="en"><head><title>Performance Tuning for the Coin Toss Model - Jim Killingsworth</title><meta charset="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta name="description" content="I wrapped up the last post expressing a desire to study the approximation technique using larger models of the coin toss game. Up until now, I was using a naive implementation of the computation method to perform the calculations—an implementation that was crudely implemented and too slow for larger models. In this post, I demonstrate an alternative approach that has a much better performance profile. I also describe a simple technique that can be used to reduce the number of iterations required when applying the hill climbing algorithm."/><base href="/"/><link rel="canonical" href="https://jkillingsworth.com/2021/07/12/performance-tuning-for-the-coin-toss-model/"/><link rel="icon" href="./static/favicon.ico" type="image/x-icon"/><link rel="icon" href="./static/favicon-256.jpg" sizes="256x256"/><link rel="preload" href="./static/fonts/open-sans-v20-latin-700.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/lora-v17-latin-regular.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/lora-v17-latin-italic.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/roboto-mono-v13-latin-regular.woff2" as="font" crossorigin/><link rel="preload" href="https://www.google-analytics.com/analytics.js" as="script"/><script src="https://www.googletagmanager.com/gtag/js?id=UA-114299226-1" async></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag("js", new Date());
  gtag("config", "UA-114299226-1", { "send_page_view": true });
</script><style>@font-face{font-display:swap;font-family:"Open Sans";font-style:normal;font-weight:700;src:local("Open Sans Bold"),local("OpenSans-Bold"),url(./static/fonts/open-sans-v20-latin-700.woff2) format("woff2"),url(./static/fonts/open-sans-v20-latin-700.woff) format("woff")}@font-face{font-display:swap;font-family:"Lora";font-style:normal;font-weight:400;src:local("Lora Regular"),local("Lora-Regular"),url(./static/fonts/lora-v17-latin-regular.woff2) format("woff2"),url(./static/fonts/lora-v17-latin-regular.woff) format("woff")}@font-face{font-display:swap;font-family:"Lora";font-style:italic;font-weight:400;src:local("Lora Italic"),local("Lora-Italic"),url(./static/fonts/lora-v17-latin-italic.woff2) format("woff2"),url(./static/fonts/lora-v17-latin-italic.woff) format("woff")}@font-face{font-display:swap;font-family:"Roboto Mono";font-style:normal;font-weight:400;src:local("Roboto Mono"),local("RobotoMono-Regular"),url(./static/fonts/roboto-mono-v13-latin-regular.woff2) format("woff2"),url(./static/fonts/roboto-mono-v13-latin-regular.woff) format("woff")}
/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:0.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace, monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace, monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}button,[type="button"],[type="reset"],[type="submit"]{-webkit-appearance:button}button::-moz-focus-inner,[type="button"]::-moz-focus-inner,[type="reset"]::-moz-focus-inner,[type="submit"]::-moz-focus-inner{border-style:none;padding:0}button:-moz-focusring,[type="button"]:-moz-focusring,[type="reset"]:-moz-focusring,[type="submit"]:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:0.35em 0.75em 0.625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type="checkbox"],[type="radio"]{box-sizing:border-box;padding:0}[type="number"]::-webkit-inner-spin-button,[type="number"]::-webkit-outer-spin-button{height:auto}[type="search"]{-webkit-appearance:textfield;outline-offset:-2px}[type="search"]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}template{display:none}[hidden]{display:none}
html{box-sizing:border-box;overflow-y:scroll}*,*::before,*::after{box-sizing:inherit}body{font-family:"Lora", "Georgia", serif;font-weight:normal;background:#fff;color:#000;display:flex;flex-flow:row wrap;font-size:12pt;justify-content:space-between;line-height:1.5;margin:0 auto;width:90%}body>*{flex:0 100%}body>header{font-size:21pt;margin:10px 0}body>footer{border-top:3px solid gray;font-size:10pt;font-style:italic;padding:16px 0}header,nav,h1,h2{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold}header a,nav a,h1 a,h2 a{color:inherit}a{color:blue;text-decoration:none}a:hover{color:blue;text-decoration:underline}strong{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold}svg{fill:currentColor}.navmenu{border-top:3px solid gray;border-bottom:1px solid #ccc}.navmenu #toggle{float:right;height:24px;margin:4px 0;width:24px}.navmenu #toggle+label{color:transparent;cursor:pointer;display:block;padding:4px 0;position:relative;user-select:none;-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none}.navmenu #toggle+label::before{background:#fff;background-size:24px;content:"";float:right;height:24px;left:24px;position:relative;width:24px}.navmenu #toggle+label::after{content:"Menu";left:0;padding:0 16px;position:absolute}.navmenu #toggle+label{border-bottom:none}.navmenu #toggle+label::before{background-image:url("./static/chevron-down.svg")}.navmenu #toggle+label::after{color:#000}.navmenu #toggle~ul{height:0;visibility:hidden}.navmenu #toggle:checked+label{border-bottom:1px solid #e6e6e6}.navmenu #toggle:checked+label::before{background-image:url("./static/chevron-up.svg")}.navmenu #toggle:checked+label::after{color:gray}.navmenu #toggle:checked~ul{height:auto;visibility:visible}.navmenu ul{display:flex;flex-flow:column wrap;list-style-type:none;justify-content:flex-start;margin:0;overflow:hidden;padding:0}.navmenu ul>li{flex:none}.navmenu ul>li a{display:block;padding:4px 16px}.navmenu ul>li a:hover,.navmenu ul>li a:focus{background:gray;color:#fff}.content{max-width:720px}.content header,.content footer,.content h1,.content h2,.content p,.content ul,.content figure{margin:24px 0}.content h1{font-size:18pt}.content h2{font-size:12pt}.content footer{font-style:italic}.content p:last-of-type::after{clear:both;content:"";display:block}.content ul{padding-left:16px}.content ul>li{margin:12px 0}.content figure{max-width:90vw}.content figure>img{display:block}.content .fig-chart{padding-top:56.25%;page-break-inside:avoid;position:relative}.content .fig-chart>img{max-height:100%;max-width:100%;position:absolute;top:0}.content .fig-latex{overflow-x:auto}.content .fig-latex>img{margin:0 16px}.content .fig-pic-l>img,.content .fig-pic-r>img{margin:0 auto;max-width:100%;object-fit:cover}.content .button{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold;background:#e6e6e6;color:inherit;display:block;margin:24px 0;padding:4px 0;text-align:center}.content .button:hover,.content .button:focus{background:gray;color:#fff}.content .message header>h1{background:#ff0;display:inline-block;font-size:12pt;margin:0;text-transform:lowercase}.content .message header>h1::first-letter{text-transform:uppercase}.content .message header>h1::after{content:":"}.content .message p{font-style:italic}.content .newpost header>h1{background:#ff0;display:inline-block;font-size:12pt;margin:0;text-transform:lowercase}.content .newpost header>h1::first-letter{text-transform:uppercase}.content .newpost header>h1::after{content:":"}.content .newpost header>h2{font-size:18pt}.content .newpost a.readmore::after{content:" \00bb"}.content .newpost a:not(.readmore):not(:hover){color:inherit}.content .oldpost{margin:24px 0}.content .oldpost header>h1{display:none}.content .archive ul>li time{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:none;font-size:10pt}.content .contact label,.content .contact input[type="submit"]{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold;cursor:pointer;display:block;margin:16px 0}.content .contact label{margin-bottom:4px}.content .contact input[type="text"],.content .contact input[type="email"],.content .contact textarea{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:block;font-size:10pt;line-height:inherit;padding:4px;width:100%}.content .contact textarea{height:200px;max-width:100%;min-width:100%}.content .contact input[type="submit"]{padding:4px 40px}.content .comments{margin:24px 0 8px}.content .comments header>h2{display:none}.content .comments noscript{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:block;font-size:10pt;margin:-12px 0 24px}.sidebar header>h1{display:none}.sidebar header>h2{border-bottom:1px solid #ccc;border-top:3px solid gray;font-size:inherit;margin:0;padding:4px 0}.sidebar section{margin:24px 0}.sidebar section:first-of-type{margin-top:0}.sidebar .social-media ul{list-style:none;padding:0 0 0 16px}.sidebar .social-media ul>li a{display:inline-block}.sidebar .social-media ul>li a *{vertical-align:middle}.sidebar .social-media ul>li a span{margin:0 10px}.sidebar .social-media ul>li a svg{color:gray;height:48px;width:48px}.sidebar .social-media ul>li a:hover svg{color:inherit}.content p:not(.nojustify),.sidebar p:not(.nojustify){text-align:justify;word-spacing:-1px}.content p,.content ul,.sidebar p,.sidebar ul{line-height:1.667}@media only screen and (min-width: 600px){.content ul{padding-left:40px}.content ul>li{margin:0}.content figure{max-width:90vw}.content .fig-latex>img{margin:0 40px}.content .fig-pic-l>img{float:left;margin:0 24px 0 0}.content .fig-pic-r>img{float:right;margin:0 0 0 24px}.content .archive ul>li time{display:inline}body{max-width:720px;width:90%}body>header{font-size:24pt}.navmenu #toggle{display:none}.navmenu #toggle+label{display:none}.navmenu #toggle~ul{height:auto;visibility:visible}.navmenu ul{flex-flow:row wrap}.navmenu ul>li a{padding:4px 32px}}@media only screen and (min-width: 1200px){body{max-width:1200px}body>header{text-align:center}.content{flex:0 60%}.sidebar{flex:0 35%}.sidebar section:first-of-type{margin-top:40px}}@media only print{.content ul{padding-left:40px}.content ul>li{margin:0}.content figure{max-width:100vw}.content .fig-latex>img{margin:0 40px}.content .fig-pic-l>img{float:left;margin:0 24px 0 0}.content .fig-pic-r>img{float:right;margin:0 0 0 24px}.content .archive ul>li time{display:inline}body{display:block;margin:auto;width:100%}body>header{border-bottom:1px solid #ccc;border-top:3px solid gray;font-size:inherit;margin:0;padding:4px 0;text-align:left}.navmenu,.sidebar,.oldpost,.comments{display:none}}@page{margin:1in 1.25in}
</style></head><body><header><a href="./">Jim Killingsworth</a></header><nav class="navmenu"><input id="toggle" type="checkbox"/><label for="toggle">Enable menu</label><ul><li><a href="./"> Home </a></li><li><a href="./archive/"> Archive </a></li><li><a href="./about/"> About </a></li><li><a href="./contact/"> Contact </a></li></ul></nav><main class="content"><article><header><h1>Performance Tuning for the Coin Toss Model</h1></header><p>I wrapped up the <a href="/2021/05/31/approximations-with-polynomials/">last post</a> express­ing a desire to study the approx­i­ma­tion tech­nique using larger mod­els of the coin toss game. Up until now, I was using a naive imple­men­ta­tion of the com­pu­ta­tion method to per­form the cal­cu­la­tion­s—an imple­men­ta­tion that was crudely imple­mented and too slow for larger mod­els. In this post, I demon­strate an alter­na­tive approach that has a much bet­ter per­formance pro­file. I also describe a sim­ple tech­nique that can be used to reduce the num­ber of iter­a­tions required when apply­ing the hill climb­ing algorithm.</p><h2 id="optimized-computation-method">Optimized Computation Method</h2><p>To get around the per­for­mance issues ref­er­enced above, I decided to imple­ment the com­pu­ta­tion method using an entirely dif­fer­ent approach. I think the best way to describe this new approach is to work through an exam­ple. Sup­pose we have a model of the coin toss game with four coin toss events per round:</p><figure class="fig-latex"><img width="42" height="14" alt="Figure 1" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-01-latex-0078029047.svg"></figure><p>Just like we did in some of the pre­vi­ous posts, we can cre­ate a graph­i­cal rep­re­sen­ta­tion of the coin toss model using a state diagram:</p><figure class="fig-latex"><img width="518" height="384" alt="Figure 2" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-02-latex-3908891078.svg"></figure><p>This dia­gram illus­trates the start­ing state and all of the pos­si­ble state tran­si­tions. In this case, we use one set of vari­ables to rep­re­sent state tran­si­tions away from the ini­tial state and another set of vari­ables to rep­re­sent state tran­si­tions towards the ini­tial state. Here is the rela­tion­ship between these two sets of vari­ables:</p><figure class="fig-latex"><img width="243" height="19" alt="Figure 3" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-03-latex-1379633680.svg"></figure><p>We want to pre­com­pute these val­ues ahead of time and look them up later instead of com­put­ing them on the fly. Since our model is sym­met­ri­cal by def­i­n­i­tion, we can assume the coin in the ini­tial state is always a fair coin:</p><figure class="fig-latex"><img width="92" height="18" alt="Figure 4" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-04-latex-1818867320.svg"></figure><p>For this exam­ple, let’s choose some arbi­trary val­ues for the remain­ing state transitions:</p><figure class="fig-latex"><img width="92" height="71" alt="Figure 5" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-05-latex-2873578394.svg"></figure><p>Now we want to cre­ate some lookup tables for our state tran­si­tion val­ues. We’ll use these lookup tables when com­put­ing the like­li­hood of land­ing on each one of the states after each toss of the coin. Let’s cre­ate two arrays and pop­u­late them with these values:</p><figure class="fig-latex"><img width="603" height="235" alt="Figure 6" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-06-latex-1999054460.svg"></figure><p>These are our lookup tables. Notice that these arrays are padded with three extra ele­ments, one in the front and two in the back. You’ll see in a minute why this is nec­es­sary. We are using point­ers to refer to the first value in each array. Now let’s do some pointer arithmetic:</p><figure class="fig-latex"><img width="264" height="62" alt="Figure 7" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-07-latex-1036861475.svg"></figure><p>One pointer is incre­ment­ed, while the other is decre­ment­ed. This effec­tively shifts these arrays, one to the right and one to the left. We want to align them in a way that makes it easy to per­form our com­pu­ta­tions later on. Here is how our lookup tables appear after the shift:</p><figure class="fig-latex"><img width="619" height="237" alt="Figure 8" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-08-latex-3148335610.svg"></figure><p>By def­i­n­i­tion, every round of the coin toss game starts out in the zero state, so we know with 100% cer­tainty what state we’re going to be in before the first coin toss. Thus, we can rep­re­sent our ini­tial state vec­tor with the fol­low­ing array:</p><figure class="fig-latex"><img width="603" height="125" alt="Figure 9" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-09-latex-0228700456.svg"></figure><p>This array is allo­cated to the same size as the arrays used for the state tran­si­tion lookup tables. And like before, we use a pointer to refer to the first value in the array. Now let’s do some more pointer arithmetic:</p><figure class="fig-latex"><img width="270" height="65" alt="Figure 10" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-10-latex-3933656041.svg"></figure><p>In this case, we cre­ate a pair of point­ers that point to two dif­fer­ent ele­ments of the same array. We can treat these two point­ers as if they were point­ers to two dif­fer­ent arrays, even though they’re really not. In essence, this is what our two arrays look like:</p><figure class="fig-latex"><img width="619" height="239" alt="Figure 11" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-11-latex-3394233061.svg"></figure><p>Now that we have arrays rep­re­sent­ing our state tran­si­tion val­ues and our ini­tial state vec­tor, along with point­ers that prop­erly align the data, we can com­pute the val­ues of the state vec­tor after each toss of the coin. Here is the algorithm:</p><figure class="fig-latex"><img width="320" height="154" alt="Figure 12" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-12-latex-3782699414.svg"></figure><p>Notice that we always dou­ble the value in the zero off­set at the end of each iter­a­tion of the outer loop. This is nec­es­sary because we are only solv­ing half the prob­lem. Since we know our model is sym­met­ri­cal, we don’t bother to cal­cu­late val­ues for tran­si­tions into the neg­a­tive states. They are always a mir­ror image of the val­ues for the pos­i­tive states. How­ev­er, we do need to con­sider the neg­a­tive state that tran­si­tions into the zero state. It is the same as the pos­i­tive state that tran­si­tions into the zero state, hence the doubling.</p><p>Here are the com­puted val­ues after outer loop iter­a­tion #1:</p><figure class="fig-latex"><img width="619" height="349" alt="Figure 13" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-13-latex-4023732679.svg"></figure><p>Here are the com­puted val­ues after outer loop iter­a­tion #2:</p><figure class="fig-latex"><img width="619" height="349" alt="Figure 14" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-14-latex-0725765104.svg"></figure><p>Here are the com­puted val­ues after outer loop iter­a­tion #3:</p><figure class="fig-latex"><img width="619" height="349" alt="Figure 15" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-15-latex-3323978084.svg"></figure><p>Here are the com­puted val­ues after outer loop iter­a­tion #4:</p><figure class="fig-latex"><img width="619" height="349" alt="Figure 16" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-16-latex-2140972058.svg"></figure><p>Once the loop ter­mi­nates, we have the prob­a­bil­i­ties of land­ing on each state after the fourth and final toss of the coin. States with a zero value are never ter­mi­nal states. The states with non-zero val­ues are the ter­mi­nal states. Here are the rel­e­vant val­ues:</p><figure class="fig-latex"><img width="89" height="71" alt="Figure 17" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-17-latex-1870717318.svg"></figure><p>Is this the most opti­mal com­pu­ta­tion method? Prob­a­bly not. For even num­bered coin toss­es, the odd num­bered states are always zero. For odd num­bered coin toss­es, the even num­bered states are always zero. We could prob­a­bly use this knowl­edge to opti­mize the inner loop even fur­ther, but it might make the algo­rithm a lit­tle more complicated.</p><p>Con­sider also that each iter­a­tion of the inner loop is inde­pen­dent of the oth­ers. This means that they can be run out of order or in par­al­lel. Since we’re using point­ers to ref­er­ence ele­ments of the state tran­si­tion lookup tables and state vec­tor arrays, we could eas­ily mod­ify our pro­gram to use hard­ware spe­cific SIMD intrin­sics such as those for the SSE or AVX instruc­tion sets. This would allow us to par­al­lelize the com­pu­ta­tions in the inner loop.</p><h2 id="counting-the-floating-point-operations">Counting the Floating Point Operations</h2><p>The exam­ple we worked through in the com­pu­ta­tion method described above is small enough that we can eas­ily count the num­ber of float­ing point oper­a­tions required to com­pute the result. Here is a ta­ble show­ing the count of all addi­tion and mul­ti­pli­ca­tion oper­a­tions needed to com­plete each iter­a­tion of the outer loop:</p><figure class="fig-latex"><img width="586" height="168" alt="Figure 18" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-18-latex-1017454915.svg"></figure><p>We can add up the total num­ber of oper­a­tions for each iter­a­tion of the outer loop to arrive at the total num­ber of oper­a­tions nec­es­sary to reach the final result:</p><figure class="fig-latex"><img width="152" height="18" alt="Figure 19" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-19-latex-2858770086.svg"></figure><p>This tells us how many oper­a­tions are required for a model with four coin toss events. But what if we’re using a much larger model of the coin toss game? The fol­low­ing ta­ble shows how to com­pute the num­ber of oper­a­tions required for any iter­a­tion of the outer loop, regard­less of the size of the coin toss model:</p><figure class="fig-latex"><img width="586" height="69" alt="Figure 20" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-20-latex-2080618346.svg"></figure><p>Now we need to add up the num­ber of oper­a­tions used in each iter­a­tion to get the total num­ber of oper­a­tions required to com­pute the final result:</p><figure class="fig-latex"><img width="126" height="50" alt="Figure 21" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-21-latex-3012764768.svg"></figure><p>This for­mula tells us the total num­ber of float­ing point oper­a­tions nec­es­sary to cal­cu­late the final result for a coin toss model with an arbi­trary num­ber of coin toss events. But I think it might be con­ve­nient to rep­re­sent this in alge­braic form instead of sum­ma­tion form. Con­sider the fol­low­ing relationship:</p><figure class="fig-latex"><img width="277" height="50" alt="Figure 22" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-22-latex-4035126405.svg"></figure><p>This is the for­mula for the tri­an­gu­lar num­ber sequence. We can use this rela­tion­ship to replace the sum­ma­tion above and present our solu­tion in the fol­low­ing alge­braic form:</p><figure class="fig-latex"><img width="107" height="41" alt="Figure 23" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-23-latex-1408902942.svg"></figure><p>As you can see, this indi­cates that our algo­rithm has qua­dratic time com­plex­i­ty. But this does­n’t tell us every­thing. How we access mem­ory and whether or not we make effi­cient use of the cache can have an impact on per­for­mance regard­less of the num­ber of float­ing point oper­a­tions required to com­plete a task.</p><h2 id="comparison-to-matrix-multiplication">Comparison to Matrix Multiplication</h2><p>In my ear­lier post titled <a href="/2021/02/25/generalizing-the-coin-toss-markov-model/"><em>Gen­er­al­iz­ing the Coin Toss Markov Model</em></a>, we inves­ti­gated a com­pu­ta­tion method based on the prod­uct of state vec­tors and state tran­si­tion matri­ces. I am curi­ous how this com­pu­ta­tion method com­pares to the opti­mized com­pu­ta­tion method ana­lyzed in the pre­vi­ous sec­tion. For this analy­sis, we’ll use the fol­low­ing notation:</p><figure class="fig-latex"><img width="266" height="90" alt="Figure 24" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-24-latex-0116377550.svg"></figure><p>We can think of the row vec­tor as a matrix with a sin­gle row. Let’s start by first count­ing the num­ber of oper­a­tions needed to com­pute the prod­uct of two square matri­ces and the num­ber of oper­a­tions needed to com­pute the prod­uct of a row vec­tor and a square matrix:</p><figure class="fig-latex"><img width="406" height="135" alt="Figure 25" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-25-latex-2997770823.svg"></figure><p>The num­ber of oper­a­tions required depends on the size of the matrix. And the size of the matrix depends on the num­ber of coin toss events we are mod­el­ing. But the num­ber of matrix oper­a­tions we need to com­pute also depends on the num­ber of coin toss events. Recall the fol­low­ing for­mula from our gen­er­al­ized coin toss Markov model:</p><figure class="fig-latex"><img width="96" height="19" alt="Figure 26" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-26-latex-2967125593.svg"></figure><p>If we are mod­el­ing a sys­tem with four coin toss events, we can expand the above as follows:</p><figure class="fig-latex"><img width="191" height="18" alt="Figure 27" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-27-latex-2444608179.svg"></figure><p>In this case, there are a total of four matrix oper­a­tions. Each matrix oper­a­tion con­tains many ele­men­tary oper­a­tions. We want to count the num­ber of ele­men­tary oper­a­tions. Since matrix mul­ti­pli­ca­tion is asso­cia­tive, we’ll get the same result whether we eval­u­ate the expres­sion from left to right or right to left­—as­sum­ing we don’t have any float­ing point round­ing errors. But the num­ber of ele­men­tary oper­a­tions required to eval­u­ate this expres­sion depends on the order in which we per­form the eval­u­a­tion. Here is the analy­sis for right-as­so­cia­tive evaluation:</p><figure class="fig-latex"><img width="405" height="135" alt="Figure 28" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-28-latex-0820374398.svg"></figure><p>Using this infor­ma­tion, we can express the total num­ber of float­ing point oper­a­tions as a func­tion of the num­ber of coin toss events:</p><figure class="fig-latex"><img width="387" height="110" alt="Figure 29" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-29-latex-2238707748.svg"></figure><p>Thus, our matrix prod­uct has a quar­tic poly­no­mial time com­plex­ity when using right-as­so­cia­tive eval­u­a­tion. We can use this for­mula to com­pute the total num­ber of ele­men­tary oper­a­tions needed for a model with four coin toss events:</p><figure class="fig-latex"><img width="82" height="18" alt="Figure 30" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-30-latex-0130141746.svg"></figure><p>This is about two orders of mag­ni­tude more than the num­ber of oper­a­tions required when using the opti­mized com­pu­ta­tion method. And the gap is even worse for mod­els with a higher num­ber of coin toss events. But the dif­fer­ence is not as bad if we eval­u­ate the matrix prod­uct from left to right instead of right to left. Here is the analy­sis for left­-as­so­cia­tive evaluation:</p><figure class="fig-latex"><img width="405" height="135" alt="Figure 31" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-31-latex-4028277795.svg"></figure><p>Using this infor­ma­tion, we can express the total num­ber of float­ing point oper­a­tions as a func­tion of the num­ber of coin toss events:</p><figure class="fig-latex"><img width="218" height="109" alt="Figure 32" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-32-latex-3214268921.svg"></figure><p>Accord­ing­ly, our matrix prod­uct has cubic poly­no­mial time com­plex­ity when using left­-as­so­cia­tive eval­u­a­tion. We can use this for­mula to com­pute the total num­ber of ele­men­tary oper­a­tions needed for a model with four coin toss events:</p><figure class="fig-latex"><img width="67" height="18" alt="Figure 33" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-33-latex-1583057697.svg"></figure><p>This is a bet­ter fig­ure, but it’s still more than ten times the num­ber of oper­a­tions required when using the opti­mized com­pu­ta­tion method. And the gap still gets worse for mod­els with a higher num­ber of coin toss events. For each com­pu­ta­tion method, we can plot the num­ber of oper­a­tions required as a func­tion of the num­ber of coin toss events to get an idea of what the growth rate of each method looks like:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 34" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-34-flop-counts.svg"></figure><p>Keep in mind that the ver­ti­cal axis has a log­a­rith­mic scale. As you can see, the opti­mized com­pu­ta­tion method scales much bet­ter than meth­ods using matrix mul­ti­pli­ca­tion. And per­haps this is not sur­pris­ing when you con­sider that, in the gen­er­al­ized coin toss mod­el, the state tran­si­tion matrix is a sparse matrix that con­tains mostly zeros. Per­form­ing addi­tion and mul­ti­pli­ca­tion oper­a­tions against those zero val­ues is a waste of com­pu­ta­tion resources.</p><h2 id="comparison-to-algebraic-manipulation">Comparison to Algebraic Manipulation</h2><p>Sup­pose we have a set of alge­braic for­mu­las that we can use to com­pute the expected out­come of the coin toss game given a set of bias­es. We might be able to cal­cu­late the results with fewer oper­a­tions than any of the meth­ods described above. In an ear­lier post titled <a href="/2019/09/14/estimating-the-weights-of-biased-coins/"><em>Esti­mat­ing the Weights of Biased Coins</em></a>, we derived a set of equa­tions to com­pute the out­come for a model of the coin toss game with four coin toss events. Let’s do some­thing sim­i­lar here:</p><figure class="fig-latex"><img width="499" height="563" alt="Figure 35" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-35-latex-1123861125.svg"></figure><p>With four coin toss events, there are six­teen pos­si­ble coin toss sequences. The ta­ble above shows the prob­a­bil­ity of each one, along with the ter­mi­nal state after the final coin toss. We can express the chance of end­ing up on each one of the final states with the following:</p><figure class="fig-latex"><img width="354" height="116" alt="Figure 36" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-36-latex-0866507655.svg"></figure><p>Remem­ber, the coin in the ini­tial state is always a fair coin. The for­mu­las above can be sim­pli­fied to con­tain fewer operations:</p><figure class="fig-latex"><img width="230" height="115" alt="Figure 37" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-37-latex-3386967422.svg"></figure><p>You might want to stop here and check my work to make sure I did this cor­rect­ly. It’s easy to make a mis­take. With these for­mu­las, we can now count all the addi­tion and mul­ti­pli­ca­tion oper­a­tions to get the total num­ber of float­ing point oper­a­tions needed to com­pute the results:</p><figure class="fig-latex"><img width="586" height="135" alt="Figure 38" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-38-latex-2070364635.svg"></figure><p>Adding up the total num­ber of oper­a­tions for each result, we find that, at least in the case where there are four coin toss events, there are fewer oper­a­tions required than with any of the com­pu­ta­tion meth­ods exam­ined in the pre­vi­ous sections:</p><figure class="fig-latex"><img width="105" height="18" alt="Figure 39" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-39-latex-3956110410.svg"></figure><p>It’s not clear to me how to gen­er­al­ize this for a model with an arbi­trary num­ber of coin toss events. How­ev­er, it is clear to me that the prob­a­bil­ity of get­ting a sequence of all heads or all tails, regard­less of the num­ber of coin toss­es, can be expressed like this:</p><figure class="fig-latex"><img width="78" height="52" alt="Figure 40" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-40-latex-3784430567.svg"></figure><p>This com­pu­ta­tion has lin­ear time com­plex­i­ty. The num­ber of oper­a­tions required is directly pro­por­tional to the num­ber of coin toss events. Know­ing this, we can assume that an approach using pre­de­ter­mined alge­braic for­mu­las has at least a lin­ear growth rate. That’s a best case sce­nar­io. But real­is­ti­cal­ly, it’s prob­a­bly not that good. Nonethe­less, this approach still might have a bet­ter per­for­mance pro­file than the opti­mized com­pu­ta­tion method we detailed ear­lier. It might be worth explor­ing this idea further.</p><h2 id="performance-bottleneck">Performance Bottleneck</h2><p>The chal­lenge with using the alge­braic approach is com­ing up with the for­mu­las for mod­els with a high num­ber of coin toss events. These for­mu­las also need to be eval­u­ated in a man­ner that has an accept­able per­for­mance pro­file. In some of the pre­vi­ous posts, I used a <a href="https://symbolics.mathdotnet.com/">com­puter alge­bra library</a> to build up expres­sion trees rep­re­sent­ing the alge­braic for­mu­las. These expres­sion trees were then mapped to a <a href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/expression-trees/">dif­fer­ent expres­sion tree format</a> and com­piled into exe­cutable functions.</p><p>This method worked beau­ti­fully for smaller mod­els of the coin toss game. But the com­pi­la­tion step turned out to be one of the per­for­mance bot­tle­necks pre­vent­ing this method from being used for larger mod­els of the coin toss game. Fur­ther­more, the exe­cutable func­tions gen­er­ated by the com­pi­la­tion step did­n’t run nearly as fast as the opti­mized com­pu­ta­tion method. I was also run­ning into stack over­flow errors when attempt­ing to solve for larger mod­els. It was unus­able for mod­els with more than about twenty coin toss events. I haven’t looked too deeply into it yet, but I think I might know what the prob­lem is. Con­sider the fol­low­ing expression:</p><figure class="fig-latex"><img width="95" height="15" alt="Figure 41" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-41-latex-2171351888.svg"></figure><p>This is just a sum of four num­bers. For this for­mu­la, the expres­sion tree gen­er­ated by the com­puter alge­bra library would look like this:</p><figure class="fig-latex"><img width="291" height="131" alt="Figure 42" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-42-latex-4028407798.svg"></figure><p>This remains a very flat tree struc­ture regard­less of how many num­bers we are adding togeth­er. Ide­al­ly, the sum would be com­piled as a loop with an accu­mu­la­tor. But that’s not what hap­pens. In prepa­ra­tion for the com­pi­la­tion step, this expres­sion tree gets mapped to a binary expres­sion tree for­mat that looks like this:</p><figure class="fig-latex"><img width="291" height="227" alt="Figure 43" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-43-latex-1218695308.svg"></figure><p>For com­plex expres­sions with many operands, this can be a very deeply nested tree struc­ture. And that’s where I think the prob­lem lies. This deep tree struc­ture might be what was caus­ing the com­pi­la­tion step to take a long time. It might also explain why the gen­er­ated func­tions ran too slowly and why the eval­u­a­tion of larger mod­els was exhaust­ing the call stack.</p><h2 id="hill-climbing-with-descending-step-sizes">Hill Climbing with Descending Step Sizes</h2><p>In some of the exam­ples we looked at in the pre­vi­ous posts, we used a hill climb­ing algo­rithm as an opti­miza­tion tech­nique to find para­me­ters that min­i­mize a cost func­tion. In all of these exam­ples, we used a fixed step size. In the last post, we used a step size that would deliver an accu­racy of five dec­i­mal places:</p><figure class="fig-latex"><img width="98" height="20" alt="Figure 44" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-44-latex-3654662009.svg"></figure><p>Con­sider the exam­ples illus­trated for the <a href="/2021/05/31/approximations-with-polynomials/#linear-polynomial">lin­ear poly­no­mial method</a> in the pre­vi­ous post. Apply­ing the hill climb­ing algo­rithm while using this value as the step size, the opti­miza­tion task took tens of thou­sands of iter­a­tions to com­plete. We can sig­nif­i­cantly reduce the num­ber of iter­a­tions nec­es­sary by using a series of tiered step sizes arranged in descend­ing order:</p><figure class="fig-latex"><img width="97" height="124" alt="Figure 45" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-45-latex-1470015507.svg"></figure><p>The objec­tive here is to run the hill climb­ing algo­rithm to com­ple­tion using the first step size. Once com­plete, the process is repeated with the next step size using the result of the pre­vi­ous run as the start­ing point. We keep repeat­ing this process until we’ve run the algo­rithm to com­ple­tion for the small­est step size. Repro­duc­ing the lin­ear poly­no­mial exam­ples from the pre­vi­ous post, here are the paths taken by the hill climb­ing algo­rithm when using descend­ing step sizes:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 46" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-46-estimate-n-10-1-heatmap.svg"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 47" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-47-estimate-n-10-2-heatmap.svg"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 48" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-48-estimate-n-10-3-heatmap.svg"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 49" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-49-estimate-n-10-4-heatmap.svg"></figure><p>Except for the last one, which drifts off into a local min­i­mum, all paths fin­ish with the same result. And this result is the same one we found when using a fixed step size. But when using descend­ing step sizes, the results con­verge in far fewer iter­a­tions. Here is a comparison:</p><figure class="fig-latex"><img width="448" height="168" alt="Figure 50" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-50-latex-1721524999.svg"></figure><p>The dif­fer­ence is off the charts. Begin­ning the hill climb­ing method with a large step size allows the process to move quickly towards the tar­get area, while the smaller step sizes enable it to zero in on a pre­cise result. The ben­e­fits are clear. And this tech­nique might be use­ful for other opti­miza­tion meth­ods as well.</p><h2 id="example-with-20-coin-tosses">Example with 20 Coin Tosses</h2><p>With the per­for­mance enhance­ments out­lined in the sec­tions above, we can now apply the poly­no­mial approx­i­ma­tion tech­nique to larger mod­els of the coin toss game. Using a model of the coin toss game with twenty coin toss events, let’s use the <a href="/2021/05/31/approximations-with-polynomials/#quadratic-polynomial">qua­dratic poly­no­mial approximation</a> tech­nique described in the pre­vi­ous post to find a set of weights that approx­i­mate the fol­low­ing tar­get distribution:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 51" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-51-target-pmfunc-n-20.svg"></figure><p>Start­ing with a set of fair coins for the ini­tial guess, we can apply the hill climb­ing algo­rithm to find an opti­mal set of weights for the biased coins. The process com­pletes after 25 iter­a­tions. Here are the results:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 52" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-52-estimate-n-20-5-biases-fitted.svg"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 53" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-53-estimate-n-20-5-pmfunc-fitted.svg"></figure><p>The results are com­puted almost instan­ta­neous­ly. With­out the opti­mized com­pu­ta­tion method, these cal­cu­la­tions would have taken about twenty sec­onds to run on my cur­rent hard­ware. And with­out the descend­ing step size opti­miza­tion, this task would have taken about thirty minutes to complete.</p><h2 id="example-with-50-coin-tosses">Example with 50 Coin Tosses</h2><p>Let’s do another exam­ple. In this one, we’ll use the <a href="/2021/05/31/approximations-with-polynomials/#cubic-polynomial">cubic poly­no­mial approximation</a> tech­nique on a model with fifty coin toss events. A model this size would be imprac­ti­cal or impos­si­ble to eval­u­ate with­out the per­for­mance opti­miza­tions chron­i­cled in this post. Here is the tar­get dis­tri­b­u­tion we want to approximate:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 54" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-54-target-pmfunc-n-50.svg"></figure><p>Start­ing with a set of fair coins for the ini­tial guess, we can apply the hill climb­ing algo­rithm to find an opti­mal set of weights for the biased coins. The process com­pletes after 1,746 iter­a­tions. Here are the results:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 55" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-55-estimate-n-50-6-biases-fitted.svg"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 56" src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-56-estimate-n-50-6-pmfunc-fitted.svg"></figure><p>This is a pretty good approx­i­ma­tion, but it is not the most opti­mal result that can be found with a cubic poly­no­mi­al. When using fair coins for the ini­tial guess, the hill climb­ing method takes a route that leads to a local min­i­mum. Also, notice that the num­ber of iter­a­tions required is two orders of mag­ni­tude more than the other exam­ples in the last two sec­tions. I have some ideas for improv­ing this tech­nique fur­ther, but I will save that dis­cus­sion for another time.</p><p class="nojustify"><a href="https://github.com/jkillingsworth/jkillingsworth.com/tree/master/src/2021-07-12-performance-tuning-for-the-coin-toss-model">Accom­pa­ny­ing source code is avail­able on GitHub.</a></p><footer><time datetime="2021-07-12">July 12, 2021</time></footer></article><section class="comments"><header><h2>Comments</h2></header><script>
    var disqus_config = function () {
      this.page.url = "https://jkillingsworth.com/2021/07/12/performance-tuning-for-the-coin-toss-model/";
      this.page.title = "Performance Tuning for the Coin Toss Model";
      this.page.identifier = "/2021/07/12/performance-tuning-for-the-coin-toss-model/";
    };
    function disqus_show() {
      var d = document, s = d.createElement("script");
      s.src = "https://jkillingsworth.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    }
    function anchor_blur() {
      var a = document.getElementById("comments");
      a.innerText = "Comments";
      a.blur();
    }
    function disqus() {
      disqus_show();
      anchor_blur();
    }
  </script><a href="javascript:disqus();" id="comments" class="button">Show comments</a><div id="disqus_thread"></div><noscript> Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript></section></main><aside class="sidebar"><header><h1>Sidebar</h1></header><section class="social-media"><header><h2>Social Media</h2></header><ul><li><a href="https://www.linkedin.com/in/jkillingsworth/"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 512 512"><path d="M417.2 64H96.8C79.3 64 64 76.6 64 93.9V415c0 17.4 15.3 32.9 32.8 32.9h320.3c17.6 0 30.8-15.6 30.8-32.9V93.9C448 76.6 434.7 64 417.2 64zM183 384h-55V213h55v171zm-25.6-197h-.4c-17.6 0-29-13.1-29-29.5 0-16.7 11.7-29.5 29.7-29.5s29 12.7 29.4 29.5c0 16.4-11.4 29.5-29.7 29.5zM384 384h-55v-93.5c0-22.4-8-37.7-27.9-37.7-15.2 0-24.2 10.3-28.2 20.3-1.5 3.6-1.9 8.5-1.9 13.5V384h-55V213h55v23.8c8-11.4 20.5-27.8 49.6-27.8 36.1 0 63.4 23.8 63.4 75.1V384z"></path></svg><span>LinkedIn</span></a></li><li><a href="https://github.com/jkillingsworth/"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 512 512"><path d="M256 32C132.3 32 32 134.9 32 261.7c0 101.5 64.2 187.5 153.2 217.9 1.4.3 2.6.4 3.8.4 8.3 0 11.5-6.1 11.5-11.4 0-5.5-.2-19.9-.3-39.1-8.4 1.9-15.9 2.7-22.6 2.7-43.1 0-52.9-33.5-52.9-33.5-10.2-26.5-24.9-33.6-24.9-33.6-19.5-13.7-.1-14.1 1.4-14.1h.1c22.5 2 34.3 23.8 34.3 23.8 11.2 19.6 26.2 25.1 39.6 25.1 10.5 0 20-3.4 25.6-6 2-14.8 7.8-24.9 14.2-30.7-49.7-5.8-102-25.5-102-113.5 0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8 0 0 1.6-.5 5-.5 8.1 0 26.4 3.1 56.6 24.1 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 30.2-21 48.5-24.1 56.6-24.1 3.4 0 5 .5 5 .5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6 0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5 0 30.7-.3 55.5-.3 63 0 5.4 3.1 11.5 11.4 11.5 1.2 0 2.6-.1 4-.4C415.9 449.2 480 363.1 480 261.7 480 134.9 379.7 32 256 32z"></path></svg><span>GitHub</span></a></li></ul></section></aside><footer> &copy; 2018&ndash;2021 Jim Killingsworth. All rights reserved. </footer></body></html>